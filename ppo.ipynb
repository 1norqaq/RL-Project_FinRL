{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd7e30a",
   "metadata": {},
   "source": [
    "# PPO Agent Training and Testing for Stock Portfolio Management\n",
    "\n",
    "This notebook implements a Proximal Policy Optimization (PPO) agent for automated stock trading with rolling window backtesting strategy. The agent is trained on DOW-30 stocks with technical indicators and tested against the Dow Jones Index benchmark.\n",
    "\n",
    "## Overview\n",
    "- **Data**: DOW-30 stocks from Yahoo Finance\n",
    "- **Agent**: Proximal Policy Optimization (PPO) via ElegantRL\n",
    "- **Environment**: StockTradingEnv with transaction costs\n",
    "- **Validation**: Rolling window approach (252-day training, 20-day validation/test periods)\n",
    "- **Benchmark**: Dow Jones Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3d83c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ“] ElegantFinRLWrapper class defined!\n",
      "[âœ“] All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import yfinance as yf\n",
    "import gymnasium as gym\n",
    "\n",
    "original_torch_load = torch.load\n",
    "\n",
    "\n",
    "def patched_torch_load(*args, **kwargs):\n",
    "    kwargs.setdefault('weights_only', False)\n",
    "    return original_torch_load(*args, **kwargs)\n",
    "\n",
    "\n",
    "torch.load = patched_torch_load\n",
    "\n",
    "original_download = yf.download\n",
    "\n",
    "\n",
    "def patched_download(*args, **kwargs):\n",
    "    kwargs.pop('proxy', None)\n",
    "    return original_download(*args, **kwargs)\n",
    "\n",
    "\n",
    "yf.download = patched_download\n",
    "\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from elegantrl.agents import AgentPPO\n",
    "from elegantrl.train.run import train_agent\n",
    "from ppo_env_wrapper import ElegantFinRLWrapper\n",
    "\n",
    "try:\n",
    "    from elegantrl.train.config import Config as Arguments\n",
    "except ImportError:\n",
    "    from elegantrl.train.config import Arguments\n",
    "\n",
    "print(\"[âœ“] All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b11c60a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 1] Loading stock data...\n",
      "[INFO] Loading validated cache '../data/finrl_dow30_cache.csv'...\n",
      "[âœ“] Cache loaded: 98616 records, Date range: 2010-01-04 to 2023-12-29\n",
      "[INFO] Train: 2010-01-07 00:00:00 â†’ 2023-10-24 00:00:00, 97244 rows\n",
      "[INFO] Test:  2023-10-25 00:00:00 â†’ 2023-11-21 00:00:00, 560 rows\n"
     ]
    }
   ],
   "source": [
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
    "\n",
    "def prepare_data(cache_file = \"../data/finrl_dow30_cache.csv\",\n",
    "        TRAIN_START_DATE = '2010-01-01',\n",
    "        TEST_END_DATE = '2023-12-30'):\n",
    "    \"\"\"\n",
    "    Load stock data from cache or download from Yahoo Finance.\n",
    "    Returns preprocessed dataframe with technical indicators.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create data directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(cache_file), exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"[INFO] Loading validated cache '{cache_file}'...\")\n",
    "        try:\n",
    "            df = pd.read_csv(cache_file)\n",
    "            df = df.drop_duplicates(subset=['date', 'tic'])\n",
    "            if len(df) > 0:\n",
    "                print(f\"[âœ“] Cache loaded: {len(df)} records, Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "                return df\n",
    "            else:\n",
    "                print(\"[!] Cache file is empty, will re-download...\")\n",
    "        except Exception as e:\n",
    "            print(f\"[!] Error loading cache: {e}, will re-download...\")\n",
    "\n",
    "    \n",
    "\n",
    "    df = YahooDownloader(start_date=TRAIN_START_DATE,\n",
    "                        end_date=TEST_END_DATE,\n",
    "                        ticker_list=DOW_30_TICKER).fetch_data()\n",
    "\n",
    "\n",
    "    print(f\"[âœ“] Data preparation complete!\")\n",
    "    print(f\"    - Total records: {len(df)}\")\n",
    "    print(f\"    - Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    print(f\"    - Unique tickers: {df['tic'].nunique()}\")\n",
    "    # print(f\"    - Complete dates: {len(valid_dates)}\")\n",
    "\n",
    "    # Add technical indicators\n",
    "    print(\"\\n[STEP 2.5] Calculating technical indicators...\")\n",
    "\n",
    "    # Define indicators to calculate\n",
    "    TECHNICAL_INDICATORS = [\"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\", \"close_30_sma\", \"close_60_sma\"]\n",
    "\n",
    "    try:\n",
    "        fe = FeatureEngineer(\n",
    "            use_technical_indicator=True,\n",
    "            tech_indicator_list=TECHNICAL_INDICATORS,\n",
    "            use_vix=False,\n",
    "            use_turbulence=False,\n",
    "            user_defined_feature=False\n",
    "        )\n",
    "        \n",
    "        df = fe.preprocess_data(df)\n",
    "        \n",
    "        # Rename close_30_sma and close_60_sma to match expected names\n",
    "        if 'close_30_sma' in df.columns:\n",
    "            df = df.rename(columns={'close_30_sma': 'close_30'})\n",
    "        if 'close_60_sma' in df.columns:\n",
    "            df = df.rename(columns={'close_60_sma': 'close_60'})\n",
    "        \n",
    "        print(f\"[âœ“] Technical indicators calculated!\")\n",
    "        print(f\"    Available columns: {df.columns.tolist()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error calculating technical indicators: {e}\")\n",
    "        print(f\"[!] Attempting alternative method...\")\n",
    "        \n",
    "        # Alternative: Calculate indicators manually using ta library\n",
    "        import ta\n",
    "        \n",
    "        df_list = []\n",
    "        for ticker in df['tic'].unique():\n",
    "            ticker_df = df[df['tic'] == ticker].copy()\n",
    "            ticker_df = ticker_df.sort_values('date')\n",
    "            \n",
    "            # Calculate indicators\n",
    "            ticker_df['macd'] = ta.trend.macd_diff(ticker_df['close'])\n",
    "            \n",
    "            bb = ta.volatility.BollingerBands(ticker_df['close'])\n",
    "            ticker_df['boll_ub'] = bb.bollinger_hband()\n",
    "            ticker_df['boll_lb'] = bb.bollinger_lband()\n",
    "            \n",
    "            ticker_df['rsi_30'] = ta.momentum.rsi(ticker_df['close'], window=30)\n",
    "            ticker_df['cci_30'] = ta.trend.cci(ticker_df['high'], ticker_df['low'], ticker_df['close'], window=30)\n",
    "            ticker_df['dx_30'] = ta.trend.adx(ticker_df['high'], ticker_df['low'], ticker_df['close'], window=30)\n",
    "            ticker_df['close_30'] = ticker_df['close'].rolling(window=30).mean()\n",
    "            ticker_df['close_60'] = ticker_df['close'].rolling(window=60).mean()\n",
    "            \n",
    "            df_list.append(ticker_df)\n",
    "        \n",
    "        df = pd.concat(df_list, ignore_index=True)\n",
    "        df = df.dropna()  # Remove rows with NaN from indicator calculation\n",
    "        \n",
    "        print(f\"[âœ“] Technical indicators calculated using ta library!\")\n",
    "\n",
    "    if df is not None and not df.empty:\n",
    "        df.to_csv(cache_file, index=False)\n",
    "        print(f\"[âœ“] Data saved to cache: {cache_file}\")\n",
    "    else:\n",
    "        print(\"[ERROR] Failed to download data or received empty dataframe\")\n",
    "        return None\n",
    "    \n",
    "    return df\n",
    "\n",
    "def split_train_test(df,\n",
    "            TRAIN_START_DATE = '2010-01-07',\n",
    "            TRAIN_END_DATE = '2023-10-24',\n",
    "            TEST_START_DATE = '2023-10-25',\n",
    "            TEST_END_DATE = '2023-11-21'):\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    df_train = df[\n",
    "        (df['date'] >= TRAIN_START_DATE) &\n",
    "        (df['date'] <= TRAIN_END_DATE)\n",
    "    ].copy()\n",
    "\n",
    "    df_test = df[\n",
    "        (df['date'] >= TEST_START_DATE) &\n",
    "        (df['date'] <= TEST_END_DATE)\n",
    "    ].copy()\n",
    "\n",
    "    print(f\"[INFO] Train: {df_train['date'].min()} â†’ {df_train['date'].max()}, \"\n",
    "          f\"{len(df_train)} rows\")\n",
    "\n",
    "    print(f\"[INFO] Test:  {df_test['date'].min()} â†’ {df_test['date'].max()}, \"\n",
    "          f\"{len(df_test)} rows\")\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "# Load data\n",
    "print(\"\\n[STEP 1] Loading stock data...\")\n",
    "df = prepare_data()\n",
    "df_train, df_test = split_train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28519ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date      close       high        low       open     volume   tic  \\\n",
      "84 2010-01-07   6.309610   6.352158   6.263767   6.344667  477131200  AAPL   \n",
      "85 2010-01-07  38.060406  38.236266  36.964656  38.155100   10371600  AMGN   \n",
      "86 2010-01-07  33.469982  33.677278  32.776346  32.895937    8981700   AXP   \n",
      "87 2010-01-07  48.468548  48.554264  45.990574  46.372398   14379100    BA   \n",
      "88 2010-01-07  39.948696  40.102682  39.265815  39.700984    5432900   CAT   \n",
      "\n",
      "    day      macd    boll_ub    boll_lb      rsi_30      cci_30       dx_30  \\\n",
      "84    3 -0.004614   6.485744   6.247635    8.575576 -112.342924   61.786706   \n",
      "85    3 -0.035976  39.389440  37.718878    0.000000 -133.333333  100.000000   \n",
      "86    3  0.040333  33.802113  31.848364   93.971096  105.083070  100.000000   \n",
      "87    3  0.172910  50.009103  42.011025  100.000000  103.114463  100.000000   \n",
      "88    3  0.025527  40.295855  39.005691  100.000000   60.985859   25.731214   \n",
      "\n",
      "     close_30   close_60  \n",
      "84   6.366690   6.366690  \n",
      "85  38.554159  38.554159  \n",
      "86  32.825238  32.825238  \n",
      "87  46.010064  46.010064  \n",
      "88  39.650773  39.650773  \n",
      "            date       close        high         low        open    volume  \\\n",
      "97328 2023-10-25  169.118011  171.055299  168.673212  169.888975  57157000   \n",
      "97329 2023-10-25  252.106812  256.303033  252.041962  254.820918   2302300   \n",
      "97330 2023-10-25  139.999374  141.286986  139.716480  140.555384   2841400   \n",
      "97331 2023-10-25  177.729996  187.000000  176.250000  186.000000  13806400   \n",
      "97332 2023-10-25  236.932816  242.572232  236.507197  241.701645   2542400   \n",
      "\n",
      "        tic  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
      "97328  AAPL    2 -1.064952  179.626394  167.153473  43.059296 -103.202742   \n",
      "97329  AMGN    2  3.331741  269.396548  239.712682  55.409777   18.982641   \n",
      "97330   AXP    2 -2.483298  151.562484  138.154793  38.720306 -125.629848   \n",
      "97331    BA    2 -6.330028  195.909043  177.463955  33.394909 -113.242511   \n",
      "97332   CAT    2 -6.167309  273.020693  235.898819  39.705723 -188.710638   \n",
      "\n",
      "           dx_30    close_30    close_60  \n",
      "97328  30.145961  173.266383  175.842247  \n",
      "97329   0.516642  251.957985  244.379989  \n",
      "97330  14.386227  147.211676  151.874403  \n",
      "97331  45.948598  191.679999  208.963666  \n",
      "97332  48.301910  258.255679  263.523816  \n",
      "['date', 'close', 'high', 'low', 'open', 'volume', 'tic', 'day', 'macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30', 'close_60']\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())\n",
    "print(df_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d733759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ“] setup_ppo_args function defined!\n"
     ]
    }
   ],
   "source": [
    "def setup_ppo_args(env_args, cwd_path):\n",
    "    args = Arguments(agent_class=AgentPPO, env_class=ElegantFinRLWrapper)\n",
    "    args.env_args = env_args\n",
    "    args.env_name = env_args['env_name']\n",
    "\n",
    "    args.net_dims = (128, 64)\n",
    "    args.state_dim = env_args['state_dim']\n",
    "    args.action_dim = env_args['action_dim']\n",
    "    args.if_discrete = env_args['if_discrete']\n",
    "\n",
    "    args.learning_rate = 1e-4\n",
    "    args.batch_size = 128\n",
    "\n",
    "    args.target_step = 2000\n",
    "    args.break_step = 40000\n",
    "\n",
    "    # Training progress and logging\n",
    "    args.worker_num = 1\n",
    "    args.eval_proc_num = 0\n",
    "    args.if_use_multi_processing = False\n",
    "    args.eval_gap = 500  # Evaluate every 500 steps to see progress\n",
    "    args.save_gap = 500  # Save checkpoint every 500 steps\n",
    "    \n",
    "    # Enable verbose output for monitoring\n",
    "    args.if_save = True\n",
    "    args.if_overwrite_save = True\n",
    "\n",
    "    args.cwd = cwd_path\n",
    "    args.if_remove = True\n",
    "    return args\n",
    "\n",
    "print(\"[âœ“] setup_ppo_args function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f19e8945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ“] real_test_inference function defined!\n"
     ]
    }
   ],
   "source": [
    "def real_test_inference(test_df, stock_dim, indicators, args):\n",
    "    params = {\n",
    "        \"df\": test_df, \"stock_dim\": stock_dim, \"hmax\": 100,\n",
    "        \"initial_amount\": 1000000, \"num_stock_shares\": [0] * stock_dim,\n",
    "        \"buy_cost_pct\": [0.001] * stock_dim,\n",
    "        \"sell_cost_pct\": [0.001] * stock_dim,\n",
    "        \"reward_scaling\": 1e-4,\n",
    "        \"state_space\": 1 + stock_dim * (len(indicators) + 2),\n",
    "        \"action_space\": stock_dim, \"tech_indicator_list\": indicators,\n",
    "        \"env_name\": \"test_inference\", \"state_dim\": 1 + stock_dim * (len(indicators) + 2),\n",
    "        \"action_dim\": stock_dim, \"if_discrete\": False, \"target_return\": 10.0\n",
    "    }\n",
    "    env = ElegantFinRLWrapper(**params)\n",
    "\n",
    "    agent = AgentPPO(args.net_dims, args.state_dim, args.action_dim)\n",
    "    # agent.save_or_load_agent(args.cwd, if_save=False)\n",
    "    agent.act.eval()\n",
    "\n",
    "    res = env.reset()\n",
    "    state = res[0] if isinstance(res, tuple) else res\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        s_tensor = torch.as_tensor((state,), dtype=torch.float32, device=agent.device)\n",
    "        with torch.no_grad():\n",
    "            action = agent.act(s_tensor).detach().cpu().numpy()[0]\n",
    "\n",
    "        step_res = env.step(action)\n",
    "        if len(step_res) == 5:\n",
    "            state, reward, term, trunc, _ = step_res\n",
    "            done = term or trunc\n",
    "        else:\n",
    "            state, reward, done, _, _ = step_res\n",
    "\n",
    "    return env.env.save_asset_memory()\n",
    "\n",
    "print(\"[âœ“] real_test_inference function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec9143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Stock dimension: 28\n",
      "[INFO] State dimension: 281\n",
      "[INFO] Training data shape: (97244, 16)\n",
      "[INFO] Test data shape: (560, 16)\n",
      "\n",
      "[STEP 6] Starting PPO Agent Training on Full Dataset...\n",
      "Training period: 2010-01-07 00:00:00 to 2023-10-24 00:00:00\n",
      "Test period: 2023-10-25 00:00:00 to 2023-11-21 00:00:00\n",
      "\n",
      "================================================================================\n",
      "[ERROR] Training failed: name 'setup_ppo_args' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/2t/p39lh5hx71794_67j85_rwlr0000gn/T/ipykernel_77217/3569747678.py\", line 57, in <module>\n",
      "    args = setup_ppo_args(env_params, cwd_path)\n",
      "NameError: name 'setup_ppo_args' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing with Full Dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ALL_INDICATORS = [\"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\", \"close_30\", \"close_60\"]\n",
    "\n",
    "# Prepare training data\n",
    "stock_dimension = len(df_train['tic'].unique())\n",
    "state_dim = 1 + stock_dimension * (len(ALL_INDICATORS) + 2)\n",
    "\n",
    "# Create day indices for training data\n",
    "train_dates = sorted(df_train['date'].unique())\n",
    "date_map_train = {date: idx for idx, date in enumerate(train_dates)}\n",
    "df_train['day'] = df_train['date'].map(date_map_train)\n",
    "df_train.set_index('day', inplace=True, drop=False)\n",
    "\n",
    "# Create day indices for test data\n",
    "test_dates = sorted(df_test['date'].unique())\n",
    "date_map_test = {date: idx for idx, date in enumerate(test_dates)}\n",
    "df_test['day'] = df_test['date'].map(date_map_test)\n",
    "df_test.set_index('day', inplace=True, drop=False)\n",
    "\n",
    "print(f\"[INFO] Stock dimension: {stock_dimension}\")\n",
    "print(f\"[INFO] State dimension: {state_dim}\")\n",
    "print(f\"[INFO] Training data shape: {df_train.shape}\")\n",
    "print(f\"[INFO] Test data shape: {df_test.shape}\")\n",
    "\n",
    "# Setup environment parameters for training\n",
    "env_params = {\n",
    "    \"env_name\": \"FinRL_PPO_Train\",\n",
    "    \"df\": df_train,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": [0] * stock_dimension,\n",
    "    \"buy_cost_pct\": [0.001] * stock_dimension,\n",
    "    \"sell_cost_pct\": [0.001] * stock_dimension,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_dim,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": ALL_INDICATORS,\n",
    "    \"state_dim\": state_dim,\n",
    "    \"action_dim\": stock_dimension,\n",
    "    \"if_discrete\": False,\n",
    "    \"target_return\": 10.0\n",
    "}\n",
    "\n",
    "print(f\"\\n[STEP 6] Starting PPO Agent Training on Full Dataset...\")\n",
    "print(f\"Training period: {df_train['date'].min()} to {df_train['date'].max()}\")\n",
    "print(f\"Test period: {df_test['date'].min()} to {df_test['date'].max()}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "try:\n",
    "    cwd_path = \"../checkpoints/ppo_full_train\"\n",
    "    os.makedirs(cwd_path, exist_ok=True)\n",
    "\n",
    "    args = setup_ppo_args(env_params, cwd_path)\n",
    "\n",
    "    print(f\"\\n[Training Configuration]\")\n",
    "    print(f\"  Network Dims: {args.net_dims}\")\n",
    "    print(f\"  Learning Rate: {args.learning_rate}\")\n",
    "    print(f\"  Batch Size: {args.batch_size}\")\n",
    "    print(f\"  Target Steps per Update: {args.target_step}\")\n",
    "    print(f\"  Total Training Steps: {args.break_step}\")\n",
    "    print(f\"  Evaluation Gap: {args.eval_gap} steps\")\n",
    "    print(f\"  Checkpoint Path: {cwd_path}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    print(\"[-->] Starting PPO Agent Training...\")\n",
    "    \n",
    "    train_agent(args)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"[âœ“] Training completed successfully!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Run inference on test data\n",
    "    print(f\"\\n[STEP 6.5] Running inference on test data...\")\n",
    "    test_results = real_test_inference(df_test, stock_dimension, ALL_INDICATORS, args)\n",
    "    \n",
    "    # Save test results\n",
    "    test_results.to_csv(\"ppo_test_results.csv\", index=False)\n",
    "    print(f\"[âœ“] Test results saved to 'ppo_test_results.csv'\")\n",
    "    print(f\"    Records: {len(test_results)}\")\n",
    "    print(f\"    Date range: {test_results['date'].min()} to {test_results['date'].max()}\")\n",
    "    \n",
    "    # Calculate and display initial performance metrics\n",
    "    initial_value = test_results['account_value'].iloc[0]\n",
    "    final_value = test_results['account_value'].iloc[-1]\n",
    "    total_return = (final_value / initial_value - 1) * 100\n",
    "    \n",
    "    print(f\"    Initial Portfolio Value: ${initial_value:,.2f}\")\n",
    "    print(f\"    Final Portfolio Value: ${final_value:,.2f}\")\n",
    "    print(f\"    Total Return: {total_return:.2f}%\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0157e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 7] Performance Analysis\n",
      "[*] Successfully loaded PPO trading records!\n",
      "    Testing period: 2023-10-25 to 2023-11-21\n",
      "    Test duration: 20 trading days\n",
      "[*] Downloading Dow Jones Index as benchmark...\n",
      "YF.download() has changed argument auto_adjust default to True\n",
      "\n",
      "================================================================================\n",
      "                 ðŸš€ PPO Agent Stock Trading Performance Report ðŸš€                 \n",
      "================================================================================\n",
      "Metric                                       PPO Strategy              Benchmark\n",
      "--------------------------------------------------------------------------------\n",
      "Cumulative Return                                   8.39%                  6.40%\n",
      "Annualized Sharpe Ratio                            7.6013                 6.8279\n",
      "Maximum Drawdown                                   -1.09%                 -1.87%\n",
      "================================================================================\n",
      "Excess Return                                       1.99%\n",
      "Sharpe Ratio Difference                            0.7734\n",
      "Max Drawdown Improvement                           -0.78%\n",
      "================================================================================\n",
      "\n",
      "[âœ“] Equity curve visualization saved to 'ppo_backtest_performance.png'!\n",
      "[âœ“] PPO Test Complete!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_metrics(df, column_name='account_value'):\n",
    "    \"\"\"Calculate key performance metrics\"\"\"\n",
    "    daily_return = df[column_name].pct_change().dropna()\n",
    "\n",
    "    cum_return = (df[column_name].iloc[-1] / df[column_name].iloc[0]) - 1\n",
    "\n",
    "    if daily_return.std() != 0:\n",
    "        sharpe_ratio = (252 ** 0.5) * (daily_return.mean() / daily_return.std())\n",
    "    else:\n",
    "        sharpe_ratio = 0\n",
    "\n",
    "    rolling_max = df[column_name].cummax()\n",
    "    drawdown = (df[column_name] - rolling_max) / rolling_max\n",
    "    max_drawdown = drawdown.min()\n",
    "\n",
    "    return cum_return, sharpe_ratio, max_drawdown\n",
    "\n",
    "\n",
    "def ppo_test():\n",
    "    \"\"\"Test PPO strategy performance and compare with benchmark\"\"\"\n",
    "    result_file = \"ppo_test_results.csv\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(result_file)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.drop_duplicates(subset=['date']).sort_values('date').reset_index(drop=True)\n",
    "\n",
    "        start_date = df['date'].iloc[0].strftime('%Y-%m-%d')\n",
    "        end_date = df['date'].iloc[-1].strftime('%Y-%m-%d')\n",
    "        initial_capital = df['account_value'].iloc[0]\n",
    "\n",
    "        print(f\"\\n[STEP 7] Performance Analysis\")\n",
    "        print(f\"[*] Successfully loaded PPO trading records!\")\n",
    "        print(f\"    Testing period: {start_date} to {end_date}\")\n",
    "        print(f\"    Test duration: {len(df)} trading days\")\n",
    "        print(f\"[*] Downloading Dow Jones Index as benchmark...\")\n",
    "\n",
    "        # Download benchmark data\n",
    "        benchmark = yf.download(\"^DJI\", start=start_date, end=end_date, progress=False)\n",
    "\n",
    "        if isinstance(benchmark.columns, pd.MultiIndex):\n",
    "            benchmark.columns = benchmark.columns.get_level_values(0)\n",
    "\n",
    "        benchmark = benchmark.reset_index()\n",
    "\n",
    "        # Unify date column name\n",
    "        if 'Date' not in benchmark.columns and 'index' in benchmark.columns:\n",
    "            benchmark = benchmark.rename(columns={'index': 'Date'})\n",
    "\n",
    "        benchmark['Date'] = pd.to_datetime(benchmark['Date'])\n",
    "\n",
    "        # Merge tables\n",
    "        df = pd.merge(df, benchmark[['Date', 'Close']], left_on='date', right_on='Date', how='left')\n",
    "        df['Close'] = df['Close'].ffill()  # Fill missing weekend/holiday data\n",
    "\n",
    "        df['benchmark_value'] = (df['Close'] / df['Close'].iloc[0]) * initial_capital\n",
    "\n",
    "        # Calculate metrics\n",
    "        ppo_ret, ppo_sharpe, ppo_mdd = calculate_metrics(df, 'account_value')\n",
    "        bm_ret, bm_sharpe, bm_mdd = calculate_metrics(df, 'benchmark_value')\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"{'ðŸš€ PPO Agent Stock Trading Performance Report ðŸš€':^80}\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"{'Metric':<34} {'PPO Strategy':>22} {'Benchmark':>22}\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Cumulative Return':<34} {ppo_ret*100:>21.2f}% {bm_ret*100:>21.2f}%\")\n",
    "        print(f\"{'Annualized Sharpe Ratio':<34} {ppo_sharpe:>22.4f} {bm_sharpe:>22.4f}\")\n",
    "        print(f\"{'Maximum Drawdown':<34} {ppo_mdd*100:>21.2f}% {bm_mdd*100:>21.2f}%\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # Calculate outperformance\n",
    "        excess_return = (ppo_ret - bm_ret) * 100\n",
    "        sharpe_diff = ppo_sharpe - bm_sharpe\n",
    "        dd_improvement = (bm_mdd - ppo_mdd) * 100\n",
    "\n",
    "        print(f\"{'Excess Return':<34} {excess_return:>21.2f}%\")\n",
    "        print(f\"{'Sharpe Ratio Difference':<34} {sharpe_diff:>22.4f}\")\n",
    "        print(f\"{'Max Drawdown Improvement':<34} {dd_improvement:>21.2f}%\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "        plt.plot(df['date'], df['account_value'], label='PPO Agent Portfolio', \n",
    "                color='#2E86AB', linewidth=2.5)\n",
    "        plt.plot(df['date'], df['benchmark_value'], label='Dow Jones Index (Benchmark)', \n",
    "                color='#A23B72', linewidth=1.5, linestyle='--', alpha=0.8)\n",
    "\n",
    "        plt.title('Proximal Policy Optimization (PPO) Stock Trading Performance', \n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.xlabel('Date', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Portfolio Value ($)', fontsize=12, fontweight='bold')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        textstr = '\\n'.join((\n",
    "            r'$\\bf{PPO\\ Strategy}$',\n",
    "            f'Return: {ppo_ret * 100:.2f}%',\n",
    "            f'Sharpe: {ppo_sharpe:.3f}',\n",
    "            f'Max DD: {ppo_mdd * 100:.2f}%',\n",
    "            '',\n",
    "            r'$\\bf{Benchmark}$',\n",
    "            f'Return: {bm_ret * 100:.2f}%',\n",
    "            f'Sharpe: {bm_sharpe:.3f}',\n",
    "            f'Max DD: {bm_mdd * 100:.2f}%',\n",
    "            '',\n",
    "            r'$\\bf{Outperformance}$',\n",
    "            f'Excess Return: {excess_return:.2f}%',\n",
    "            f'Sharpe Diff: {sharpe_diff:.3f}'\n",
    "        ))\n",
    "        props = dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray', linewidth=1.5)\n",
    "        plt.gca().text(0.02, 0.98, textstr, transform=plt.gca().transAxes, fontsize=9.5,\n",
    "                       verticalalignment='top', bbox=props, family='monospace')\n",
    "\n",
    "        plt.legend(loc='lower right', fontsize=11, framealpha=0.95)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save figure\n",
    "        fig_path = 'ppo_backtest_performance.png'\n",
    "        plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"[âœ“] Equity curve visualization saved to '{fig_path}'!\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] An error occurred during testing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "# Run PPO test\n",
    "ppo_test()\n",
    "print(\"[âœ“] PPO Test Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "472a34ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 9] Test Results Visualization\n",
      "================================================================================\n",
      "[*] Loading PPO test results...\n",
      "    Test period: 2023-10-25 to 2023-11-21\n",
      "    Trading days: 20\n",
      "[*] Downloading Dow Jones benchmark data...\n",
      "\n",
      "[âœ“] Test results visualization saved to 'ppo_test_analysis.png'!\n",
      "\n",
      "================================================================================\n",
      "                        Test Period Performance Summary                         \n",
      "================================================================================\n",
      "Metric                                    PPO Agent            Benchmark\n",
      "--------------------------------------------------------------------------------\n",
      "Cumulative Return                             8.39%                6.40%\n",
      "Annualized Sharpe Ratio                       7.601                6.828\n",
      "Maximum Drawdown                             -1.09%               -1.87%\n",
      "Excess Return                                 1.99%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Visualization: Plot Test Results with Benchmark\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_test_results():\n",
    "    \"\"\"Plot PPO test results against benchmark\"\"\"\n",
    "    try:\n",
    "        # Load test results\n",
    "        result_file = \"ppo_test_results.csv\"\n",
    "        \n",
    "        if not os.path.exists(result_file):\n",
    "            print(f\"[!] Test results file not found: {result_file}\")\n",
    "            print(\"    Please run the training cell (cell 7) first\")\n",
    "            return\n",
    "        \n",
    "        df = pd.read_csv(result_file)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.drop_duplicates(subset=['date']).sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        start_date = df['date'].iloc[0].strftime('%Y-%m-%d')\n",
    "        end_date = df['date'].iloc[-1].strftime('%Y-%m-%d')\n",
    "        initial_capital = df['account_value'].iloc[0]\n",
    "        \n",
    "        print(f\"[*] Loading PPO test results...\")\n",
    "        print(f\"    Test period: {start_date} to {end_date}\")\n",
    "        print(f\"    Trading days: {len(df)}\")\n",
    "        print(f\"[*] Downloading Dow Jones benchmark data...\")\n",
    "        \n",
    "        # Download benchmark\n",
    "        benchmark = yf.download(\"^DJI\", start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        if isinstance(benchmark.columns, pd.MultiIndex):\n",
    "            benchmark.columns = benchmark.columns.get_level_values(0)\n",
    "        \n",
    "        benchmark = benchmark.reset_index()\n",
    "        \n",
    "        if 'Date' not in benchmark.columns and 'index' in benchmark.columns:\n",
    "            benchmark = benchmark.rename(columns={'index': 'Date'})\n",
    "        \n",
    "        benchmark['Date'] = pd.to_datetime(benchmark['Date'])\n",
    "        \n",
    "        # Merge with benchmark\n",
    "        df = pd.merge(df, benchmark[['Date', 'Close']], left_on='date', right_on='Date', how='left')\n",
    "        df['Close'] = df['Close'].ffill()\n",
    "        df['benchmark_value'] = (df['Close'] / df['Close'].iloc[0]) * initial_capital\n",
    "        \n",
    "        # Calculate metrics\n",
    "        ppo_ret = (df['account_value'].iloc[-1] / df['account_value'].iloc[0] - 1) * 100\n",
    "        bm_ret = (df['benchmark_value'].iloc[-1] / df['benchmark_value'].iloc[0] - 1) * 100\n",
    "        \n",
    "        ppo_daily = df['account_value'].pct_change().dropna()\n",
    "        bm_daily = df['benchmark_value'].pct_change().dropna()\n",
    "        \n",
    "        ppo_sharpe = (252 ** 0.5) * (ppo_daily.mean() / ppo_daily.std()) if ppo_daily.std() != 0 else 0\n",
    "        bm_sharpe = (252 ** 0.5) * (bm_daily.mean() / bm_daily.std()) if bm_daily.std() != 0 else 0\n",
    "        \n",
    "        ppo_max = df['account_value'].cummax()\n",
    "        ppo_dd = ((df['account_value'] - ppo_max) / ppo_max).min() * 100\n",
    "        \n",
    "        bm_max = df['benchmark_value'].cummax()\n",
    "        bm_dd = ((df['benchmark_value'] - bm_max) / bm_max).min() * 100\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(18, 8))\n",
    "        \n",
    "        # Plot 1: Portfolio Value Comparison\n",
    "        ax1.plot(df['date'], df['account_value'], label='PPO Agent Portfolio', \n",
    "                color='#2E86AB', linewidth=2.5)\n",
    "        ax1.plot(df['date'], df['benchmark_value'], label='Dow Jones Index (Benchmark)', \n",
    "                color='#A23B72', linewidth=2, linestyle='--', alpha=0.8)\n",
    "        \n",
    "        ax1.set_title('PPO Agent Test Period Performance vs Benchmark', \n",
    "                     fontsize=16, fontweight='bold', pad=15)\n",
    "        ax1.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('Portfolio Value ($)', fontsize=12, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend(loc='lower right', fontsize=11, framealpha=0.95)\n",
    "        \n",
    "        # Add metrics text box\n",
    "        textstr = '\\n'.join((\n",
    "            r'$\\bf{PPO\\ Strategy}$',\n",
    "            f'Return: {ppo_ret:.2f}%',\n",
    "            f'Sharpe: {ppo_sharpe:.3f}',\n",
    "            f'Max DD: {ppo_dd:.2f}%',\n",
    "            '',\n",
    "            r'$\\bf{Benchmark}$',\n",
    "            f'Return: {bm_ret:.2f}%',\n",
    "            f'Sharpe: {bm_sharpe:.3f}',\n",
    "            f'Max DD: {bm_dd:.2f}%'\n",
    "        ))\n",
    "        props = dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray', linewidth=1.5)\n",
    "        ax1.text(0.02, 0.98, textstr, transform=ax1.transAxes, fontsize=10,\n",
    "                verticalalignment='top', bbox=props, family='monospace')\n",
    "        \n",
    "        # Plot 2: Daily Returns Comparison\n",
    "        ppo_returns = df['account_value'].pct_change() * 100\n",
    "        bm_returns = df['benchmark_value'].pct_change() * 100\n",
    "        \n",
    "        ax2.plot(df['date'], ppo_returns, label='PPO Daily Return', \n",
    "                color='#2E86AB', linewidth=1.5, alpha=0.7)\n",
    "        ax2.plot(df['date'], bm_returns, label='Benchmark Daily Return', \n",
    "                color='#A23B72', linewidth=1.5, alpha=0.7, linestyle='--')\n",
    "        ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "        \n",
    "        ax2.set_title('Daily Returns Comparison', fontsize=14, fontweight='bold', pad=10)\n",
    "        ax2.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "        ax2.set_ylabel('Daily Return (%)', fontsize=12, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend(loc='lower right', fontsize=10, framealpha=0.95)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = 'ppo_test_analysis.png'\n",
    "        plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\n[âœ“] Test results visualization saved to '{fig_path}'!\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"{'Test Period Performance Summary':^80}\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"{'Metric':<30} {'PPO Agent':>20} {'Benchmark':>20}\")\n",
    "        print(\"-\"*80)\n",
    "        print(f\"{'Cumulative Return':<30} {ppo_ret:>19.2f}% {bm_ret:>19.2f}%\")\n",
    "        print(f\"{'Annualized Sharpe Ratio':<30} {ppo_sharpe:>20.3f} {bm_sharpe:>20.3f}\")\n",
    "        print(f\"{'Maximum Drawdown':<30} {ppo_dd:>19.2f}% {bm_dd:>19.2f}%\")\n",
    "        print(f\"{'Excess Return':<30} {(ppo_ret - bm_ret):>19.2f}%\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to plot test results: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Run visualization\n",
    "print(\"\\n[STEP 9] Test Results Visualization\")\n",
    "print(\"=\"*80)\n",
    "plot_test_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
